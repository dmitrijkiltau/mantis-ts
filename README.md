# MANTIS

_Minimal Adaptive Neural Tool-Integrated System_ is a versatile AI assistant designed to be a user-friendly interface for various AI models and tools. It aims to simplify interactions with AI technologies, making them accessible to a broader audience.

## Design Principles

- Deterministic over creative
- Contracts over prompts
- Failure is explicit
- Small models decide, larger models execute
- Retries are bounded

## Orchestrator

`assistant/src/orchestrator.ts` contains an `Orchestrator` class that renders contract prompts and exposes the associated validators so the decision logic described in `ARCHITECTURE` can be exercised programmatically.

The bridge between the orchestrator and the contracts lives in the `ContractPrompt` envelope, which bundles the prompt text, the target model, and the retry guidance for each contract. `ToolSchema` provides the shape for tool argument extraction schemas, and the orchestrator ships helpers like `buildIntentClassificationPrompt`, `buildToolArgumentPrompt`, `buildStrictAnswerPrompt`, and `buildResponseFormattingPrompt` so callers do not need to re-implement the template logic. Each `validate*` helper feeds the raw model output through the contract validators before progressing.

Tone is fixed: the orchestrator injects the predefined MANTIS personality instructions into strict answer and response formatting prompts so every response keeps the same concise, technically steady voice without an extra selection contract.

## Runner

`assistant/src/runner.ts` glues the orchestrator to a model client (via the `LLMClient` interface) and replays the retry hints defined inside each contract. `Runner.executeContract` builds the `ModelInvocation`, waits for the client to return raw text, stores the result inside `AttemptRecord` entries, and re-renders the retry instructions before every new attempt using `getRetryInstruction`. That keeps the retry budget implicit, lets validators stay deterministic.

## Tools

`assistant/src/tools/registry.ts` exports the registry of available tools organized by category:

- **Local**: `clipboard`, `filesystem`, `search`
- **Web**: `fetch`, `http`
- **System**: `datetime`

Each tool definition includes a name, description, schema for arguments, and an execute function. The pipeline derives tool intents from this registry (e.g., `tool.fetch`, `tool.datetime`) and extracts arguments according to each tool's schema.

## Contracts

`assistant/src/contracts/registry.ts` aggregates all validators that enforce strict input/output behavior:

- **Intent Classification**: Routes user input to appropriate tool or answer
- **Language Detection**: Identifies user's language for preserved context
- **Tool Argument Extraction**: Validates and extracts arguments for selected tool
- **Text Transformation**: Optional text processing
- **Scoring/Evaluation**: Evaluates and scores responses
- **Strict Answer**: Generates answers without tool execution
- **Response Formatting**: Optionally formats responses as concise sentences in user's language
- **Error Channel**: Handles validation failures and routing errors

## Pipeline

`assistant/src/pipeline.ts` wires the decision pipeline together. It detects the user's language at the start, runs intent classification against tool-derived intents, extracts tool arguments when a `tool.*` intent is detected, executes the matching tool, and falls back to strict answers or the error channel when needed. Successful responses are optionally formatted as concise single sentences in the user's detected language via the response formatting contract before returning, with the predefined MANTIS tone applied to both strict answer and formatting prompts.

## Desktop App

`desktop` contains a Tauri/Vite UI that wires `Orchestrator`, `Runner`, and `OllamaClient` together. The renderer lets you type a question, pushes it through the strict answer contract, and renders each attempt so you can watch the retry guidance overlaying the result. The Rust backend (`desktop/src-tauri`) is a minimal host that simply launches the webview and exposes no custom commands.

The UI features a **Fallout-inspired retro-futuristic theme** with terminal green colors, scanline effects, and a Vault-Tec-style avatar. Styling is centralized in `desktop/src/assets/css/theme.css` using Tailwind CSS v4 with custom theme tokens.

To run the desktop experience:
1. Ensure Rust 1.72+ and the Tauri CLI are installed.
2. `cd desktop && npm install` (installs Vite and the @tauri-apps toolchain).
3. `npm run tauri` (launches the Vite dev server, then `tauri dev`).
4. `npm run tauri:build` after `npm run build` to produce bundles.

The UI expects Ollama to be listening on `http://127.0.0.1:11434` so `OllamaClient` can resolve the prompts generated by the orchestrator.

## Further Documentation

- [ARCHITECTURE](docs/ARCHITECTURE.md) - Overview of the system architecture and design principles.
